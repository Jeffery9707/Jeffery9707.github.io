<!DOCTYPE HTML>
<html lang="en">
<head>
  <title>Zhaoyang Xia</title>

  <meta http-equiv="content-type"          content="text/html; charset=UTF-8">
  <meta name="author"                      content="zhaoyang xia">
  <meta name="viewport"                    content="width=device-width, initial-scale=1.0">
  <link rel="icon"                         type="image/png"  href="images/logos/photo.jpeg">
  <link rel="shortcut icon"                type="image/png"  href="images/logos/photo.jpeg">
  <link rel="apple-touch-icon"             href="images/logos/photo.jpeg" sizes="57x57" />
  <link rel="stylesheet"                   href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css"   href="style.css">
</head>

<body>

  <!-- Part1 => Brief Bio, Photo and CV/LinkeIn/Github/Email -->
  <div class="container">
    <table align="center" border="0" cellpadding="20" width="900">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            
            <p align="center"><font size="6px">Zhaoyang Xia</font><br>Ph.D. student @ Rutgers | zx149@rutgers.edu</p>
            
            <p>I am a Ph.D. student in the Department of Computer Science at <a href="https://www.cs.rutgers.edu/">Rutgers University</a>, advised by Distinguished Professor <a href="https://scholar.google.com/citations?user=a7VNhCIAAAAJ&hl=en&oi=ao">Dimitris Metaxas</a>. Piror to this, I finished my Master Program in Computer science (Data Science track) at Rutgers. I studied mathamtics and data science when I was an undergraduate student in Fudan University.</a>

            <p>My current research interests lie primarily in generative models, such as diffusion models and Large Language Models. I am also interested in representation learning, video/image understanding, such as action detection, object segmentation or action recognition. My previous projects are about utilizing generative models and image animation models for applications in video anonymization. I also have experience in using multi-modal large language models for applications such as visual storytelling and ideation.
            </p>

            <p> <a href="Zhaoyang_cv_25_09.pdf"><img src="images/logos/cv-logo.png" height="16"></a> &nbsp; | &nbsp; 
                <a href="www.linkedin.com/in/zhaoyang-xia-7b6477192" target="_blank"><img src="images/logos/linkedin-logo.png" height="16"></a>  &nbsp; | &nbsp;
                <a href="https://github.com/Jeffery9707" target="_blank" ><img src="images/logos/github.jpeg" height="16"></a> 
          </p>
          </td>

          <td width="30%">
            <div class="photo">
              <img src="images/logos/photo.jpg">
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>

<!-- ------------------------------------------------------------------------------------ -->

  <!-- Part2 => Education -->
  <div class="container">
    <h2>Education</h2>
    <div class="education">
      <div class="timeline">
        <div class="timeline-resume">
          
          <div class="timeline-item">
            <img src="images/logos/rutgers-logo.jpeg" class="timeline-logo">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Sept. 2021 - Present</span>
            </div>
            <h5 class="timeline-title">Rutgers Univeristy</h5>
            <div class="timeline-job-title">
              Ph.D. Student in Computer Science (GPA: 4.0/4.0)
            </div>
            <ul>
              <li><b>Advisor:</b> <a href="https://scholar.google.com/citations?user=a7VNhCIAAAAJ&hl=en">Dimitris N. Metaxas</a></li>
            </ul>
          </div>
          <div class="timeline-item">
            <img src="images/logos/rutgers-logo.jpeg" class="timeline-logo">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Sept. 2019 - May. 2021</span>
            </div>
            <h5 class="timeline-title">Rutgers Univeristy</h5>
            <div class="timeline-job-title">
              Master Student in Computer Science (Data Science) (GPA: 3.91/4.0)
            </div>
          </div>
      
          
          <div class="timeline-item">
            <img src="images/logos/fudan-logo.png" class="timeline-logo">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Sept. 2015 - Jun. 2019</span>
            </div>
            <h5 class="timeline-title">Fudan University</h5>
            <div class="timeline-job-title">
              B.S. in Information and Computing Science (Big Data & Technology)
            </div>
            <ul>
              <li><b>Advisor:</b> <a href="http://kw.fudan.edu.cn/people/yangdeqing/">Deqing Yang</a></li>
            </ul>
          </div>          
        
        </div>
      </div>
    </div>
  </div>
  <br>

<!-- ------------------------------------------------------------------------------------ -->

  <!-- Part3 => Experience -->
  <div class="container">
    <h2>Experience</h2>
    <div class="experience">
      <div class="timeline">
        <div class="timeline-resume">
           <!-- 5: Adobe Internship -->
          <div class="timeline-item">
            <img src="images/logos/adobe-logo.png" class="timeline-logo" width="80" height="80">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>May. 2025 - Present</span>
            </div>
            <h5 class="timeline-title">Adobe Inc. </h5>
            <div class="timeline-job-title">
              Research Scientist/Engineer Intern. Mentors: Somdeb Sarkhel, Mehrab Tanjim, Christine Dierk, Uttaran Bhattacharya, Viet Lai
            </div>
            <ul><li>Designed personalized MLLM-as-the-judge framework for design evaluation leveraging users' historical data.</li></ul>

          </div> 
          <!-- 4: Adobe Internship -->
          <div class="timeline-item">
            <img src="images/logos/adobe-logo.png" class="timeline-logo" width="80" height="80">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>May. 2024 - Aug. 2024</span>
            </div>
            <h5 class="timeline-title">Adobe Inc. </h5>
            <div class="timeline-job-title">
              Research Scientist/Engineer Intern. Mentors: Somdeb Sarkhel, Mehrab Tanjim, Stefano Petrangeli, Ishita Dasgupta, Saayan Mitra
            </div>
            <ul><li>Designed novel generative AI for visual storytelling methods (visual story ideation) using multi-modal large language models.</li></ul>
            <ul><li>VISIAR: Empower MLLM for Visual Story Ideation<a href="https://aclanthology.org/2025.findings-acl.945.pdf"></br>[ACL'25 Findings]</a></li></ul>
            <ul><li>Patent Filed</a></li></ul>

          </div> 
          <!-- 3: Adobe Internship -->
          <div class="timeline-item">
            <img src="images/logos/adobe-logo.png" class="timeline-logo" width="80" height="80">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>May. 2023 - Dec. 2023</span>
            </div>
            <h5 class="timeline-title">Adobe Inc. </h5>
            <div class="timeline-job-title">
              Research Scientist/Engineer Intern. Mentors: Somdeb Sarkhel, Stefano Petrangeli, Uttaran Bhattacharya, Nikos Vlassis, Saayan Mitra
            </div>
            <ul><li>Designed algorithms for improving diffusion models with human preference data</li></ul>
          </div> 

          <!-- 2: Department of Computer Science, Rutgers University. Piscataway, NJ, USA -->
          <div class="timeline-item">
            <img src="images/logos/rutgers-logo.jpeg" class="timeline-logo">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Sept. 2020 - Present</span>
            </div>
            <h5 class="timeline-title">Rutgers University. Piscataway, NJ, USA </h5>
            <div class="timeline-job-title">
              Research Assistant. Advisor: Prof. Dimitris N. Metaxas
            </div>
            <ul><li>DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization<a href="https://aclanthology.org/2024.signlang-1.44.pdf"></br>[LREC'24 Workshop]</a></li></ul>
            <ul><li>Sign language video anonymization.<a href="https://www.sign-lang.uni-hamburg.de/lrec/pub/22038.pdf"></br>[LREC'22, Sign-Lang Workshop]</a></li></ul>
            <ul><li>American Sign Language Video Anonymization to Support Online Participation of Deaf and Hard of Hearing Users </br><a href="https://dl.acm.org/doi/pdf/10.1145/3441852.3471200">[ASSET]</a></li></ul>
            <ul><li>Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images.<a href="https://arxiv.org/pdf/2203.02846.pdf">[MICCAI'21]</a></li></ul>
  
          </div>  
          <!-- 2: Department of Computer Science, Fudan University. Shanghai, China -->
          <div class="timeline-item">
            <img src="images/logos/fudan-logo.png" class="timeline-logo">
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Oct. 2018 - Aug. 2019</span>
            </div>
            <h5 class="timeline-title">Fudan University. Shanghai, China</h5>
            <div class="timeline-job-title">
              Research Assistant. Advisor: Prof. Deqing Yang
            </div>
            <ul><li> Explainable Recommendation System for Movies </a></li></ul>
            <ul><li> The Knowledge Graph Integration </a></li></ul>
          
          </div>  
          <!-- 2: Internship. Shanghai, China -->
          <div class="timeline-item">
<!--             <img src="images/logos/misumi-logo.png" class="timeline-logo"> -->
            <div class="timeline-date">
              <div class="timeline-dot"></div>
                <span>Oct. 2018 - Feb. 2019</span>
            </div>
            <h5 class="timeline-title">MISUMI (China) precision machinery trading co., LTD, Shanghai, China</h5>
            <div class="timeline-job-title">
              Data Science Intern.
            </div>
            <ul><li> Predict the loss of customers based on customer behavior data. </a></li></ul>
            <ul><li> Chat context analysis: Find the hot topics from the chat history by NLP technology. </a></li></ul>

          
          </div> 

          


        </div>
      </div>
    </div>
  </div>
  <br>

<!-- ------------------------------------------------------------------------------------ -->

  <!-- Part4 => Publications -->
  <!-- [Project Page] [Paper] [Code] [Dataset] [Bibtex] : use only relevant fields in that order -->
  <div class="container">
    <h2> Publications </h2>
    
    <!-- VISIAR-->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/visiar.png" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b>VISIAR: Empower MLLM for Visual Story Ideation</b></a>
              <div class="paper">
                [<a href="https://aclanthology.org/2025.findings-acl.945.pdf">Paper</a>]
                [<a href="https://github.com/Jeffery9707/VISIAR">Demos</a>]
                [<a onclick='if (document.getElementById("xia:22038:sign-lang:lrec").style.display=="none") document.getElementById("xia:22038:sign-lang:lrec").style.display="block"; else document.getElementById("xia:22038:sign-lang:lrec").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="xia:22038:sign-lang:lrec" style="display: none;">
                  <pre>
@inproceedings{xia2025visiar,
  title={VISIAR: Empower MLLM for Visual Story Ideation},
  author={Xia, Zhaoyang and Sarkhel, Somdeb and Tanjim, Mehrab and Petrangeli, Stefano and Dasgupta, Ishita and Chen, Yuxiao and Xu, Jinxuan and Liu, Di and Mitra, Saayan and Metaxas, Dimitris N},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={18384--18402},
  year={2025}
}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>  
    
    <!-- Sign Anonymization Diff-->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/example3.gif" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b>DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization</b></a>
              <div class="paper">
                [<a href="https://aclanthology.org/2024.signlang-1.44.pdf">Paper</a>]
                [<a href="https://github.com/Jeffery9707/DiffSLVA2">Demos</a>]
                [<a onclick='if (document.getElementById("xia:22038:sign-lang:lrec").style.display=="none") document.getElementById("xia:22038:sign-lang:lrec").style.display="block"; else document.getElementById("xia:22038:sign-lang:lrec").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="xia:22038:sign-lang:lrec" style="display: none;">
                  <pre>
@inproceedings{xia2024diffusion,
  title={Diffusion models for Sign Language video anonymization},
  author={Xia, Zhaoyang and Zhou, Yang and Han, Ligong and Neidle, Carol and Metaxas, Dimitris N},
  booktitle={Proceedings of the LREC-COLING 2024 11th Workshop on the Representation and Processing of Sign Languages: Evaluation of Sign Language Resources},
  pages={395--407},
  year={2024}
}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>    
    
    <!-- Sign Anonymization -->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/ASL.gif" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b>Sign Language Video Anonymization</b></a>
              <br>
              <strong>Zhaoyang Xia</strong>, Yuxiao Chen, Qilong Zhangli, Matt Huenerfauth, Carol Neidle and Dimitri Metaxas
              <br><em>Proceedings of the 10th Workshop on the Representation and Processing of Sign Languages (sign-lang@LREC 2022)</em>
              <div class="paper">
                [<a href="https://www.sign-lang.uni-hamburg.de/lrec/pub/22038.pdf">Paper</a>]
                [<a href="https://github.com/Jeffery9707/Sign-Language-Video-Anonymization">Demos</a>]
                [<a onclick='if (document.getElementById("xia:22038:sign-lang:lrec").style.display=="none") document.getElementById("xia:22038:sign-lang:lrec").style.display="block"; else document.getElementById("xia:22038:sign-lang:lrec").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="xia:22038:sign-lang:lrec" style="display: none;">
                  <pre>
@inproceedings{xia:22038:sign-lang:lrec,
  author    = {Xia, Zhaoyang and Chen, Yuxiao and Zhangli, Qilong and Huenerfauth, Matt and Neidle, Carol and Metaxas, Dimitris},
  title     = {Sign Language Video Anonymization},
  pages     = {202--211},
  editor    = {Efthimiou, Eleni and Fotinea, Stavroula-Evita and Hanke, Thomas and Hochgesang, Julie A. and Kristoffersen, Jette and Mesch, Johanna and Schulder, Marc},
  booktitle = {Proceedings of the {LREC2022} 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources},
  maintitle = {13th International Conference on Language Resources and Evaluation ({LREC} 2022)},
  publisher = {{European Language Resources Association (ELRA)}},
  address   = {Marseille, France},
  day       = {25},
  month     = jun,
  year      = {2022},
  isbn      = {979-10-95546-86-3},
  language  = {english},
  url       = {https://www.sign-lang.uni-hamburg.de/lrec/pub/22038.pdf}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>    

    <!-- Sign -->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/sign_face.png" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b> American sign language video anonymization to support online participation of deaf and hard of hearing users</b></a>
              <br>
              Sooyeon Lee, Abraham Glasser, Becca Dingman, <strong>Xia, Zhaoyang</strong>, Dimitris Metaxas, Carol Neidle, and Matt Huenerfauth.
              <br><em>ASSET</em>
              <div class="paper">
                [<a href="https://dl.acm.org/doi/pdf/10.1145/3441852.3471200">Paper</a>]
                [<a href="https://github.com/Jeffery9707/American-Sign-Language-Video-Anonymization-to-Support-Online-Participation">Demos</a>]
                [<a onclick='if (document.getElementById("lee2021american").style.display=="none") document.getElementById("lee2021american").style.display="block"; else document.getElementById("lee2021american").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="lee2021american" style="display: none;">
                  <pre>
@inproceedings{lee2021american,
  title={American Sign Language Video Anonymization to Support Online Participation of Deaf and Hard of Hearing Users},
  author={Lee, Sooyeon and Glasser, Abraham and Dingman, Becca and Xia, Zhaoyang and Metaxas, Dimitris and Neidle, Carol and Huenerfauth, Matt},
  booktitle={The 23rd International ACM SIGACCESS Conference on Computers and Accessibility},
  pages={1--13},
  year={2021}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>
    
        <!-- Skeleton Pre-train -->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/skeleton.png" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b> Hierarchically self-supervised transformer for human skeleton representation learning </b></a>
              <br>
              Yuxiao Chen, Long Zhao, Jianbo Yuan, Yu Tian, <strong>Xia, Zhaoyang</strong>, Shijie Geng, Ligong Han, and Dimitris N. Metaxas.
              <br><em>ECCV 2022</em>
              <div class="paper">
                [<a href="https://arxiv.org/pdf/2207.09644.pdf">Paper</a>]
                [<a onclick='if (document.getElementById("chen2022hierarchically").style.display=="none") document.getElementById("chen2022hierarchically").style.display="block"; else document.getElementById("chen2022hierarchically").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="chen2022hierarchically" style="display: none;">
                  <pre>
@inproceedings{chen2022hierarchically,
  title={Hierarchically Self-supervised Transformer for Human Skeleton Representation Learning},
  author={Chen, Yuxiao and Zhao, Long and Yuan, Jianbo and Tian, Yu and Xia, Zhaoyang and Geng, Shijie and Han, Ligong and Metaxas, Dimitris N},
  booktitle={European Conference on Computer Vision (\textbf{ECCV})},
  pages={185--202},
  year={2022},
  organization={Springer}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>   
    
    <!-- TransFusion -->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/TransFusion.png" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b>TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers</b></a>
              <br>
              Di Liu, Yunhe Gao, Qilong Zhangli, Ligong Han, Xiaoxiao He, <strong>Xia, Zhaoyang</strong>, Song Wen, Qi Chang, Zhennan Yan, Mu Zhou, et al.
              <br><em>MICCAI 2022</em>
              <div class="paper">
                [<a href="https://arxiv.org/pdf/2203.10726">Paper</a>]
                [<a onclick='if (document.getElementById("liu2022transfusion").style.display=="none") document.getElementById("liu2022transfusion").style.display="block"; else document.getElementById("liu2022transfusion").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="liu2022transfusion" style="display: none;">
                  <pre>
@inproceedings{liu2022transfusion,
  title={Transfusion: multi-view divergent fusion for medical image segmentation with transformers},
  author={Liu, Di and Gao, Yunhe and Zhangli, Qilong and Han, Ligong and He, Xiaoxiao and Xia, Zhaoyang and Wen, Song and Chang, Qi and Yan, Zhennan and Zhou, Mu and others},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={485--495},
  year={2022},
  organization={Springer}
}
                  </pre>             
              </div>

            </td> 
          </td>
      </table>
    </div>    
    
    
    <!-- Region Proposal Rectification -->
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
          <td width="40%" valign="center"><img src="images/pubs/RPR.png" width="180" height="100" style="border-style: none">
            <td width="60%" valign="top">
              <a><b>Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images</b></a>
              <br>
              Qilong Zhangli, Jingru Yi, Di Liu, Xiaoxiao He, <strong>Zhaoyang Xia</strong>, Haiming Tang, He Wang, Mu Zhou, Dimitris Metaxas
              <br><em>MICCAI 2022</em>
              <div class="paper">
                [<a href="https://arxiv.org/pdf/2203.02846">Paper</a>]
                [<a onclick='if (document.getElementById("zhangli2022region").style.display=="none") document.getElementById("zhangli2022region").style.display="block"; else document.getElementById("zhangli2022region").style.display="none";'>Bibtex</a>]
                <div class="BibtexExpand" id="zhangli2022region" style="display: none;">
                  <pre>
@article{zhangli2022region,
  title={Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images},
  author={Zhangli, Qilong and Yi, Jingru and Liu, Di and He, Xiaoxiao and Xia, Zhaoyang and Tang, Haiming and Wang, He and Zhou, Mu and Metaxas, Dimitris},
  journal={arXiv preprint arXiv:2203.02846},
  year={2022}
}
                  </pre>             
              </div>
            </td> 
          </td>
      </table>
    </div>
  

    
    

 

    

    

   
    
  </div>
  <br>

  <!-- ------------------------------------------------------------------------------------ -->
  <!-- Part5 => Presentation -->
<!--   <div class="container">
    <h2>Presentation</h2>
    <div class="presentation">
      <div>
        <br>
        <p align="justify">Hu J, Guan A, <b>Zhangli Q</b>, Sayadi R, Hamdan US, Vyas RM. Harnessing Machine Learning to Personalize Cleft Lip Markings (Oral). 89th Annual Meeting of the American Society of Plastic Surgeons (ASPS), San Francisco, CA. Oct 2020. “Top 100 Abstract” Published in PRS Global Open.</p>
        https://journals.lww.com/prsgo/Fulltext/2020/09001/Harnessing_Machine_learning_to_Personalize_Cleft.206.aspx
        <br>

        <p align="justify">Sayadi LR, Hu J, Guan A, <b>Zhangli Q</b>, Hamdan US, Vyas RM. Harnessing Machine Learning to Place Cleft Lip Markings (Oral, Resident Section). 89th Annual Meeting of the American Society of Plastic Surgeons (ASPS), San Francisco, CA. Oct 2020.</p>
        <br>

        <p align="justify">Hu J, <b>Zhangli Q</b>, Guan A, Zhang J, Millares E, Sayadi L, Hamdan US, Vyas RM. Using Machine Learning to Develop an Artificial Intelligence Algorithm that Guides Nasolabial Repair (Oral). 78th Annual Meeting of the American Cleft Palate-Craniofacial Association (ACPA). Raleigh, NC. May 2021.</p>
        https://journals.sagepub.com/doi/pdf/10.1177/1055665621999916
        <br>

        <p align="justify">Sayadi L, Hu J, Guan A, <b>Zhangli Q</b>, Hamdan US, Vyas RM. Using Machine Learning to Develop an Artificial Intelligence Algorithm that Guides Nasolabial Repair. 71st Annual Meeting of the California Society of Plastic Surgeons (CSPS). Monterey, CA. May 2021.</p>
        https://californiaplasticsurgeons.org/meeting/program/2021/
        <br>

        <p align="justify"> Dimitris Metaxas, Carol Neidle, Matt Huenerfauth, Akhter Amin, Konstantinos Dafnis, Sooyeon Lee, Zhaoyang Xia, <b>Qilong Zhangli</b>, Yuxiao Chen, Saad Hassan, Tingfeng Li, Fangzheng Wu. AI/ML-based Facial Analytics for Natural Language. National Science Foundation(NSF): Convergence Accelerator Expo 2021. Online. July 2021.</p>
        https://nsf-ca.vfairs.com/en/hall, http://www.bu.edu/asllrp/facial-analytics.html#
        <br>
        
        <p align="justify">Vyas RM, Ibrahim T, Sayadi LR, <b>Zhangli Q</b>, Chahine E, Annan B, Hamdan US, Majumder A. Combining AI and AR for Knowledge and Skill Transfer in Cleft Surgery. 4th International Comprehensive Cleft Care Workshop (CCCW). Istanbul, Turkey. Oct 7, 2021.</p>
        https://www.eventsquid.com/event.cfm?id=11534

      </div>
    </div>
  <br> -->
  <!-- Part6 => Credits to John and Georgia -->
<!--     <p style="text-align:right;"> Stolen from <a href="https://jonbarron.info/">Jon Barron</a> and <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>
  </div>
  <br>
 -->
  
    <!-- Part6 => Credits to John and Georgia -->
    <p style="text-align:right;"> Templete stolen from <a href="https://jonbarron.info/">Jon Barron</a> and <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>
  </div>
  </div>

  <br>
  </body>
</html>








  


